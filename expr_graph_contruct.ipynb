{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from autolearner.model import *\n",
    "from autolearner.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [Generate Base Data]\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "tri_temp = torch.tensor([[0.0,0.0], [0.1,.1], [.2,0.0]])\n",
    "tri_hori = torch.tensor([[0.0,0.0], [0.1,.1], [.0,.2]])\n",
    "\n",
    "def make_data(num_samples = 3):\n",
    "    all_data = []\n",
    "    for i in range(num_samples):\n",
    "        scene = []\n",
    "        n_rect = random.randint(1,1)\n",
    "        n_tri = random.randint(0,1)\n",
    "        n_house = random.randint(0,1)\n",
    "        n_ship = random.randint(0,1)\n",
    "        scale = 0.8\n",
    "\n",
    "        for n in range(n_rect):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"rect\",0.15 + pos[0],0.15 + pos[1],0.15,0.15]\n",
    "            )\n",
    "\n",
    "        for n in range(n_tri):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"tri\", tri_hori * 1.0 + torch.tensor(pos)]\n",
    "            )\n",
    "\n",
    "        for n in range(n_house):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"rect\",0.15 + pos[0],0.15 + pos[1],0.15,0.15]\n",
    "            )\n",
    "            scene.append(\n",
    "                [\"tri\", tri_temp * 1.2 + torch.tensor([0.11,0.3]) + torch.tensor(pos)]\n",
    "            )\n",
    "        \n",
    "        for n in range(n_ship):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"rect\",0.15 + pos[0],0.13 + pos[1],0.17,0.08],\n",
    "            )\n",
    "            scene.append(\n",
    "                [\"tri\", tri_hori * 1.0 + torch.tensor([0.21,0.21]) + torch.tensor(pos)]\n",
    "            )\n",
    "        scene_data = {}\n",
    "        scene_data[\"scene\"] = scene\n",
    "        all_data.append(scene_data)\n",
    "    return all_data\n",
    "\n",
    "def render(data, ax):\n",
    "    for obj in data:\n",
    "        if obj[0] == \"rect\":\n",
    "            rect = plt.Rectangle(obj[1:3],obj[3],obj[4], color=\"red\")\n",
    "            ax.add_patch(rect)\n",
    "        if obj[0] == \"tri\":\n",
    "            poly = plt.Polygon(obj[1],color=\"blue\")\n",
    "            ax.add_patch(poly)\n",
    "\n",
    "pos = (0.2,0.2)\n",
    "data = [\n",
    "    [\"rect\",0.15 + pos[0],0.13 + pos[1],0.17,0.08],\n",
    "    [\"tri\", tri_hori * 1.0 + torch.tensor([0.21,0.21]) + torch.tensor(pos)]\n",
    "    ]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "ax.cla()\n",
    "\n",
    "data = make_data(1)[0][\"scene\"]\n",
    "\n",
    "render(data, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expat(tens, dim, num):\n",
    "    rp_tens = tens.unsqueeze(dim)\n",
    "    rp_shape = [1 for o in rp_tens.shape]\n",
    "    rp_shape[dim] = num\n",
    "    output_tensor = rp_tens.repeat(rp_shape)\n",
    "    return output_tensor\n",
    "\n",
    "def group_concrete(x, batch = True):\n",
    "    assert x.min() >= 0.0,print(\"invalid x < 0.0\",x)\n",
    "    assert x.min() <= 1.0,print(\"invalid x > 1.0\",x)\n",
    "    if batch:\n",
    "        x_square = x * x\n",
    "        concrete_scores = x_square.sum(-1).sum(-1) / x.sum(-1).sum(-1)\n",
    "        return concrete_scores\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is a Graph Abstraction Module that performs graph level segmentation with regularization of natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Graph Learner Module]\n",
    "\n",
    "class GraphAttention(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, latent_dim = 128):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_dim, latent_dim, bias = False)\n",
    "        self.a = nn.Linear(latent_dim * 2, 1, bias = False)\n",
    "    \n",
    "    def forward(self, x, edges):\n",
    "        wx = self.W(x)\n",
    "        attn = self.a(wx)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GraphLearner(nn.Module):\n",
    "    def __init__(self, n_slots = 3, feature_dim = 32):\n",
    "        super().__init__()\n",
    "        self.rect_embedding = nn.Linear(1,1)\n",
    "        self.tri_embedding = nn.Linear(1,1)\n",
    "\n",
    "        # [2] Object Centric Keys\n",
    "        self.keys = nn.Parameter(torch.randn([n_slots, feature_dim]))\n",
    "\n",
    "        # [3] Neuro-Symolic Executor\n",
    "        self.executor = SceneProgramExecutor(config)    \n",
    "\n",
    "    def forward(self, input_graph):\n",
    "        outputs = {}\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Train Representation]\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataset, epochs = 100, ckpt_itrs = 20):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_loader = DataLoader(dataset, batch_size = 1, shuffle= True)\n",
    "    itr = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 2e-4)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for sample in train_loader:\n",
    "            outputs = model(sample[\"image\"].to(device))\n",
    "\n",
    "            masks = outputs[\"masks\"]\n",
    "            B, N, W, H = masks.shape\n",
    "            scores = outputs[\"scores\"]\n",
    "            features = outputs[\"features\"]\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            qa_pairs = sample[\"question\"]\n",
    "\n",
    "            for b in range(B):\n",
    "                for i,qa_pair in enumerate(qa_pairs):  \n",
    "                    programs = qa_pair[\"program\"]\n",
    "                    answers = qa_pair[\"answer\"]              \n",
    "                    kwargs = {\n",
    "                    \"end\":[scores[b]],\n",
    "                    \"features\":[features[b]]}\n",
    "\n",
    "                    q = model.executor.parse(programs[b])\n",
    "                    o = model.executor(q,**kwargs)\n",
    "                    ans = answers[b]\n",
    "                    \n",
    "                    if ans in [\"True\",\"False\"]:\n",
    "                        if itr % ckpt_itrs == 0:print(q,o[\"end\"].sigmoid().detach().numpy(),ans)\n",
    "                        if ans == \"True\":\n",
    "                            loss -= torch.log(torch.sigmoid(o[\"end\"]))\n",
    "                        else: loss -=  torch.log(1 - torch.sigmoid(o[\"end\"]))\n",
    "                    else:\n",
    "                        if itr % ckpt_itrs == 0:print(q,o[\"end\"].detach().numpy()-1, float(answers[b]))\n",
    "                        loss += torch.nn.functional.mse_loss(torch.tensor(float(answers[b])), o[\"end\"]) * 1.0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if itr % ckpt_itrs == 0:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.domain = \"demo\"\n",
    "config.concept_type = \"cone\"\n",
    "config.concept_dim = 32\n",
    "glearner = GraphLearner(4, 32)\n",
    "\n",
    "#print(glearner.executor.all_embeddings()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e46093c771f9510c4aabf3710bfb1355e5f870a13f8c22092f45d4d23626d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Melkor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
