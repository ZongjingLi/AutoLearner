{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Taichi] version 1.7.0, llvm 15.0.7, commit 7b58b0ff, osx, python 3.9.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 11/13/23 10:46:32.153 1181546] [shell.py:_shell_pop_print@23] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# [Generate Base Data]\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "tri_temp = torch.tensor([[0.0,0.0], [0.1,.1], [.2,0.0]])\n",
    "tri_hori = torch.tensor([[0.0,0.0], [0.1,.1], [.0,.2]])\n",
    "\n",
    "def make_data(num_samples = 3):\n",
    "    all_data = []\n",
    "    for i in range(num_samples):\n",
    "        scene = []\n",
    "        n_rect = random.randint(1,1)\n",
    "        n_tri = random.randint(0,1)\n",
    "        n_house = random.randint(0,1)\n",
    "        n_ship = random.randint(0,1)\n",
    "        scale = 0.8\n",
    "\n",
    "        for n in range(n_rect):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"rect\",0.15 + pos[0],0.15 + pos[1],0.15,0.15]\n",
    "            )\n",
    "\n",
    "        for n in range(n_tri):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"tri\", tri_hori * 1.0 + torch.tensor(pos)]\n",
    "            )\n",
    "\n",
    "        for n in range(n_house):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"rect\",0.15 + pos[0],0.15 + pos[1],0.15,0.15]\n",
    "            )\n",
    "            scene.append(\n",
    "                [\"tri\", tri_temp * 1.2 + torch.tensor([0.11,0.3]) + torch.tensor(pos)]\n",
    "            )\n",
    "        \n",
    "        for n in range(n_ship):\n",
    "            pos = [ random.random() * scale, random.random() *scale]\n",
    "            scene.append(\n",
    "                [\"rect\",0.15 + pos[0],0.13 + pos[1],0.17,0.08],\n",
    "            )\n",
    "            scene.append(\n",
    "                [\"tri\", tri_hori * 1.0 + torch.tensor([0.21,0.21]) + torch.tensor(pos)]\n",
    "            )\n",
    "        scene_data = {}\n",
    "        scene_data[\"scene\"] = scene\n",
    "        all_data.append(scene_data)\n",
    "    return all_data\n",
    "\n",
    "def render(data, ax):\n",
    "    for obj in data:\n",
    "        if obj[0] == \"rect\":\n",
    "            rect = plt.Rectangle(obj[1:3],obj[3],obj[4], color=\"red\")\n",
    "            ax.add_patch(rect)\n",
    "        if obj[0] == \"tri\":\n",
    "            poly = plt.Polygon(obj[1],color=\"blue\")\n",
    "            ax.add_patch(poly)\n",
    "\n",
    "pos = (0.2,0.2)\n",
    "data = [\n",
    "    [\"rect\",0.15 + pos[0],0.13 + pos[1],0.17,0.08],\n",
    "    [\"tri\", tri_hori * 1.0 + torch.tensor([0.21,0.21]) + torch.tensor(pos)]\n",
    "    ]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "ax.cla()\n",
    "\n",
    "data = make_data(1)[0][\"scene\"]\n",
    "\n",
    "render(data, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expat(tens, dim, num):\n",
    "    rp_tens = tens.unsqueeze(dim)\n",
    "    rp_shape = [1 for o in rp_tens.shape]\n",
    "    rp_shape[dim] = num\n",
    "    output_tensor = rp_tens.repeat(rp_shape)\n",
    "    return output_tensor\n",
    "\n",
    "def group_concrete(x, batch = True):\n",
    "    assert x.min() >= 0.0,print(\"invalid x < 0.0\",x)\n",
    "    assert x.min() <= 1.0,print(\"invalid x > 1.0\",x)\n",
    "    if batch:\n",
    "        x_square = x * x\n",
    "        concrete_scores = x_square.sum(-1).sum(-1) / x.sum(-1).sum(-1)\n",
    "        return concrete_scores\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is a Graph Abstraction Module that performs graph level segmentation with regularization of natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Graph Learner Module]\n",
    "\n",
    "class GraphAttention(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, latent_dim = 128):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_dim, latent_dim, bias = False)\n",
    "        self.a = nn.Linear(latent_dim * 2, 1, bias = False)\n",
    "    \n",
    "    def forward(self, x, edges):\n",
    "        wx = self.W(x)\n",
    "        attn = self.a(wx)\n",
    "\n",
    "        return x\n",
    "\n",
    "class GraphLearner(nn.Module):\n",
    "    def __init__(self, n_slots = 3, feature_dim = 32):\n",
    "        super().__init__()\n",
    "        self.rect_embedding = nn.Linear(1,1)\n",
    "        self.tri_embedding = nn.Linear(1,1)\n",
    "\n",
    "        # [2] Object Centric Keys\n",
    "        self.keys = nn.Parameter(torch.randn([n_slots, feature_dim]))\n",
    "\n",
    "        # [3] Neuro-Symolic Executor\n",
    "        self.executor = SceneProgramExecutor(config)    \n",
    "\n",
    "    def forward(self, input_graph):\n",
    "        outputs = {}\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Train Representation]\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, dataset, epochs = 100, ckpt_itrs = 20):\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_loader = DataLoader(dataset, batch_size = 1, shuffle= True)\n",
    "    itr = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 2e-4)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for sample in train_loader:\n",
    "            outputs = model(sample[\"image\"].to(device))\n",
    "\n",
    "            masks = outputs[\"masks\"]\n",
    "            B, N, W, H = masks.shape\n",
    "            scores = outputs[\"scores\"]\n",
    "            features = outputs[\"features\"]\n",
    "\n",
    "            loss = 0.0\n",
    "\n",
    "            qa_pairs = sample[\"question\"]\n",
    "\n",
    "            for b in range(B):\n",
    "                for i,qa_pair in enumerate(qa_pairs):  \n",
    "                    programs = qa_pair[\"program\"]\n",
    "                    answers = qa_pair[\"answer\"]              \n",
    "                    kwargs = {\n",
    "                    \"end\":[scores[b]],\n",
    "                    \"features\":[features[b]]}\n",
    "\n",
    "                    q = model.executor.parse(programs[b])\n",
    "                    o = model.executor(q,**kwargs)\n",
    "                    ans = answers[b]\n",
    "                    \n",
    "                    if ans in [\"True\",\"False\"]:\n",
    "                        if itr % ckpt_itrs == 0:print(q,o[\"end\"].sigmoid().detach().numpy(),ans)\n",
    "                        if ans == \"True\":\n",
    "                            loss -= torch.log(torch.sigmoid(o[\"end\"]))\n",
    "                        else: loss -=  torch.log(1 - torch.sigmoid(o[\"end\"]))\n",
    "                    else:\n",
    "                        if itr % ckpt_itrs == 0:print(q,o[\"end\"].detach().numpy()-1, float(answers[b]))\n",
    "                        loss += torch.nn.functional.mse_loss(torch.tensor(float(answers[b])), o[\"end\"]) * 1.0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if itr % ckpt_itrs == 0:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.domain = \"demo\"\n",
    "config.concept_type = \"cone\"\n",
    "config.concept_dim = 32\n",
    "glearner = GraphLearner(4, 32)\n",
    "\n",
    "#print(glearner.executor.all_embeddings()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a47e46093c771f9510c4aabf3710bfb1355e5f870a13f8c22092f45d4d23626d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Melkor')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
